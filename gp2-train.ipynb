{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3.7\n",
    "# -*- coding: utf-8 -*-\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_v2_behavior()\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils.capture import capture_output\n",
    "from IPython.display import Image, clear_output\n",
    "from pprint import pprint, pformat\n",
    "from os import path, makedirs\n",
    "from tqdm.auto import tqdm\n",
    "from random import randint\n",
    "from typing import List\n",
    "from enum import Enum\n",
    "from os import path\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.keys import Runs, Actions, Models, Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"run_name\":        Runs.umbrum,\n",
    "    \"action\":          Actions.TRAIN,\n",
    "    \"model_name\":      Models.M774,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = path.join('corpus', config[\"run_name\"], f'{config[\"run_name\"]}.{config[\"model_name\"]}.npz').replace('+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(path.isfile(corpus)):\n",
    "    gpt2.encode_dataset(\n",
    "        file_path=path.join('corpus', config[\"run_name\"], f'{config[\"run_name\"]}.txt'),\n",
    "        out_path=path.join('corpus', config[\"run_name\"], f'{config[\"run_name\"]}.{config[\"model_name\"]}.npz'),\n",
    "        model_name=config[\"model_name\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_train = {\n",
    "    \"dataset\":                       corpus,\n",
    "#    \"steps\":                         200,\n",
    "    \"model_name\":                    config[\"model_name\"],\n",
    "    \"batch_size\":                    3,\n",
    "    \"learning_rate\":                 0.000001,\n",
    "    \"accumulate_gradients\":          20,\n",
    "    \"run_name\":                      config[\"run_name\"],\n",
    "    \"sample_every\":                  20,\n",
    "    \"sample_length\":                 620,\n",
    "    \"sample_num\":                    1,\n",
    "    \"save_every\":                    20,\n",
    "    \"print_every\":                   1,\n",
    "    \"max_checkpoints\":               3,\n",
    "    \"allow_huge\":                    True,\n",
    "    \"only_train_transformer_layers\": False,\n",
    "    \"use_memory_saving_gradients\":   True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_gen = {\n",
    "    \"run_name\":          config[\"run_name\"],\n",
    "    \"return_as_list\":    True,\n",
    "    \"prefix\":            Keys.START_KEY + PROMPT,\n",
    "    \"truncate\":          Keys.END___KEY,\n",
    "    \"sample_delim\":      ' SEPARATOR '.center(80, \"-\"),\n",
    "    \"nsamples\":          12,\n",
    "    \"batch_size\":        3,\n",
    "    \"length\":            200,\n",
    "    \"temperature\":       0.6,\n",
    "    \"include_prefix\":    True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(t: str) -> List[str]:\n",
    "    return list(s for s in t.replace(Keys.END___KEY, '').rstrip().lstrip().strip().split(Keys.START_KEY) if s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lclean(l: list):\n",
    "    return [clean(t) for t in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.isdir(path.join(\"models\", config[\"model_name\"])):\n",
    "    gpt2.download_gpt2(model_name=config[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(path.isfile(corpus)):\n",
    "    gpt2.encode_dataset(\n",
    "        file_path=path.join('corpus', config[\"run_name\"], f'{config[\"run_name\"]}.txt'),\n",
    "        out_path=path.join('corpus', config[\"run_name\"], f'{config[\"run_name\"]}.{config[\"model_name\"]}.npz'),\n",
    "        model_name=config[\"model_name\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess(server=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (config[\"action\"] == Actions.PULL):\n",
    "    for model in [\"1558M\", \"774M\", \"355M\", \"345M\", \"124M\", \"117M\"]:\n",
    "        if not path.isdir(path.join(\"models\", model)):\n",
    "            gpt2.download_gpt2(model_name=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (config[\"action\"] == Actions.GRAPH):\n",
    "    dot = Digraph(comment='GPT-2')\n",
    "    for op in tqdm(tf.get_default_graph().get_operations(), leave=False):\n",
    "        op_name = op.name.replace('/', '_').replace(':', '_').lower()\n",
    "        dot.node(op_name, op_name, shape='square')\n",
    "        for i in op.inputs:\n",
    "            i_name = i.name.replace('/', '_').replace(':', '_').lower()\n",
    "            dot.node(i_name, i_name, shape=\"circle\")\n",
    "            dot.edge(i_name, op_name)\n",
    "        for o in op.outputs:\n",
    "            o_name = o.name.replace('/', '_').replace(':', '_').lower()\n",
    "            dot.node(o_name, o_name, shape=\"circle\")\n",
    "            dot.edge(op_name, o_name)\n",
    "    x = dot.render(filename='hiper_gpt2.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if   (config[\"action\"] == Actions.TRAIN):\n",
    "    gpt2.finetune(sess, **config_train)\n",
    "elif (config[\"action\"] == Actions.GENERATE):\n",
    "    gpt2.load_gpt2(sess, run_name=config['run_name'])\n",
    "    gpt2.generate(sess, **config_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
